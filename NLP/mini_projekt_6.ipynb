{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6115/294544994.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "# sns.set()\n",
    "\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "# import torchvision\n",
    "# from torchvision.utils import save_image\n",
    "# from torchvision.datasets import FashionMNIST\n",
    "# from torchvision.transforms import v2\n",
    "# from torchvision.datasets import ImageFolder\n",
    "# from torch.nn.functional import one_hot\n",
    "\n",
    "# from pytorch_fid import fid_score\n",
    "\n",
    "# from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kuba/.local/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import *\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location not palace excellent hotel booke dthe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>respite definitely not place stay looking ultr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stunning truly memorable spot right beach nusa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solid business hotel near embassy stayed hotel...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nice place make sure lock money warning money ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating\n",
       "0  location not palace excellent hotel booke dthe...       4\n",
       "1  respite definitely not place stay looking ultr...       3\n",
       "2  stunning truly memorable spot right beach nusa...       4\n",
       "3  solid business hotel near embassy stayed hotel...       3\n",
       "4  nice place make sure lock money warning money ...       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../../data'\n",
    "reviews = pd.read_csv(f\"{PATH}/train_data.csv\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "4    7243\n",
       "3    4831\n",
       "2    1747\n",
       "1    1434\n",
       "0    1137\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z komórki wyżej wynika, że dane treningowe są niezbilansowane. \\\n",
    "Znamy 2 główne metody \"naprawy\" tego problemu: undersampling i oversampling. \\\n",
    "Zdecydowaliśmy się zastosować metodę undersamplingu, w nadziei, że prawie 1200 wierszy dla każdej z klas wystarczy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews.filter(['review'])\n",
    "y = reviews.filter(['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(sampling_strategy=\"not minority\")\n",
    "resampled_train_data, resampled_train_classes = sampler.fit_resample(X_train, y_train)\n",
    "resampled_test_data, resampled_test_classes = sampler.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0         790\n",
       "1         790\n",
       "2         790\n",
       "3         790\n",
       "4         790\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_train_classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0         347\n",
       "1         347\n",
       "2         347\n",
       "3         347\n",
       "4         347\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_test_classes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Łącznie, resampled_train_classes oraz resampled_test_classes mają po 1137 w każdej z klas. \\\n",
    "\\\n",
    "Najpierw podzieliliśmy początkowy zbiór testowy na nowe dane testowe i walidacyjne, a następnie zbilansowaliśmy dane testowe otrzymane w wyniku podziału. Kolejność tych operacji jest ważna, ponieważ chcemy, aby zbiór walidacyjny nie zawierał żadnych zmian (aby zbiór walidacyjny był jak najbliższy \"rzeczywistym\" danym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = pd.merge(resampled_train_data, resampled_train_classes, left_index=True, right_index=True)\n",
    "resampled_test = pd.merge(resampled_test_data, resampled_test_classes, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>disappointed service there-the restaurant open...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13177</th>\n",
       "      <td>run thought picking cheap hotel save lot, not,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>rating suspect, hotel sofitel june 6-7 power w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>words, ok stay riu hotel punta cana, twice sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>n't fooled price location grade room damrak ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating\n",
       "4635   disappointed service there-the restaurant open...       0\n",
       "13177  run thought picking cheap hotel save lot, not,...       0\n",
       "5778   rating suspect, hotel sofitel june 6-7 power w...       0\n",
       "3526   words, ok stay riu hotel punta cana, twice sta...       0\n",
       "982    n't fooled price location grade room damrak ho...       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    790\n",
       "1    790\n",
       "2    790\n",
       "3    790\n",
       "4    790\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Rekurencyjny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "corpus = api.load('text8')\n",
    "gensim_model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size, emb_weights, bidirectional = False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if bidirectional:\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.embeddings = nn.Embedding.from_pretrained(emb_weights)\n",
    "        self.embeddings.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size*self.bidirectional, out_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "\n",
    "    def forward(self, x, len_x, hidden):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        last_seq_items = all_outputs[range(all_outputs.shape[0]), len_x]\n",
    "        out = last_seq_items\n",
    "        x = self.fc(out)\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = torch.FloatTensor(gensim_model.wv.vectors)\n",
    "embedding = nn.Embedding.from_pretrained(emb_weights)\n",
    "tokenizer = gensim_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (embeddings): Embedding(71290, 100)\n",
       "  (lstm): LSTM(100, 100)\n",
       "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = LSTMRegressor(100, 100, 1, 5, emb_weights).to(device)\n",
    "lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby usprawnić działanie metody BoW, zastosujemy tzw. \"stopwords\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kuba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Data cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    \"\"\"Function to convert a review to a string of words.\n",
    "    The input is a single string (a raw moviw review), and the output is a single string (a preprocessed movie review)\"\"\"\n",
    "    review_text = BeautifulSoup(raw_review, 'lxml').get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    meaningful_words = [word for word in words if not word in stops]\n",
    "    return \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 200 of 16392\n",
      "Review 400 of 16392\n",
      "Review 600 of 16392\n",
      "Review 800 of 16392\n",
      "Review 1000 of 16392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6115/3593606712.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(raw_review, 'lxml').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1200 of 16392\n",
      "Review 1400 of 16392\n",
      "Review 1600 of 16392\n",
      "Review 1800 of 16392\n",
      "Review 2000 of 16392\n",
      "Review 2200 of 16392\n",
      "Review 2400 of 16392\n",
      "Review 2600 of 16392\n",
      "Review 2800 of 16392\n",
      "Review 3000 of 16392\n",
      "Review 3200 of 16392\n",
      "Review 3400 of 16392\n",
      "Review 3600 of 16392\n",
      "Review 3800 of 16392\n",
      "Review 4000 of 16392\n",
      "Review 4200 of 16392\n",
      "Review 4400 of 16392\n",
      "Review 4600 of 16392\n",
      "Review 4800 of 16392\n",
      "Review 5000 of 16392\n",
      "Review 5200 of 16392\n",
      "Review 5400 of 16392\n",
      "Review 5600 of 16392\n",
      "Review 5800 of 16392\n",
      "Review 6000 of 16392\n",
      "Review 6200 of 16392\n",
      "Review 6400 of 16392\n",
      "Review 6600 of 16392\n",
      "Review 6800 of 16392\n",
      "Review 7000 of 16392\n",
      "Review 7200 of 16392\n",
      "Review 7400 of 16392\n",
      "Review 7600 of 16392\n",
      "Review 7800 of 16392\n",
      "Review 8000 of 16392\n",
      "Review 8200 of 16392\n",
      "Review 8400 of 16392\n",
      "Review 8600 of 16392\n",
      "Review 8800 of 16392\n",
      "Review 9000 of 16392\n",
      "Review 9200 of 16392\n",
      "Review 9400 of 16392\n",
      "Review 9600 of 16392\n",
      "Review 9800 of 16392\n",
      "Review 10000 of 16392\n",
      "Review 10200 of 16392\n",
      "Review 10400 of 16392\n",
      "Review 10600 of 16392\n",
      "Review 10800 of 16392\n",
      "Review 11000 of 16392\n",
      "Review 11200 of 16392\n",
      "Review 11400 of 16392\n",
      "Review 11600 of 16392\n",
      "Review 11800 of 16392\n",
      "Review 12000 of 16392\n",
      "Review 12200 of 16392\n",
      "Review 12400 of 16392\n",
      "Review 12600 of 16392\n",
      "Review 12800 of 16392\n",
      "Review 13000 of 16392\n",
      "Review 13200 of 16392\n",
      "Review 13400 of 16392\n",
      "Review 13600 of 16392\n",
      "Review 13800 of 16392\n",
      "Review 14000 of 16392\n",
      "Review 14200 of 16392\n",
      "Review 14400 of 16392\n",
      "Review 14600 of 16392\n",
      "Review 14800 of 16392\n",
      "Review 15000 of 16392\n",
      "Review 15200 of 16392\n",
      "Review 15400 of 16392\n",
      "Review 15600 of 16392\n",
      "Review 15800 of 16392\n",
      "Review 16000 of 16392\n",
      "Review 16200 of 16392\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "clean_reviews = []\n",
    "num_reviews = reviews['review'].size\n",
    "\n",
    "for review in reviews['review']:\n",
    "    i += 1\n",
    "    if i % 200 == 0:\n",
    "        print('Review {} of {}'.format(i, num_reviews))\n",
    "    clean_reviews.append(review_to_words(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "Bag of words completed\n"
     ]
    }
   ],
   "source": [
    "print('Creating the bag of words...')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 1000)\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocaulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data_features = train_data_features.toarray()\n",
    "print('Bag of words completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_train_classes = resampled_train_classes.to_numpy().flatten()\n",
    "flatten_test_classes = resampled_test_classes.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.rand(len(reviews))>0.3\n",
    "train_data = torch.from_numpy(train_data_features).float()[train_indices]\n",
    "train_targets = torch.from_numpy(reviews['rating'].values[train_indices]).long()\n",
    "\n",
    "test_data = torch.from_numpy(train_data_features[~train_indices]).float()\n",
    "test_targets = torch.from_numpy(reviews['rating'].values[~train_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = torch.from_numpy(train_data_features).float()\n",
    "# train_targets = torch.from_numpy(flatten_train_classes).long()\n",
    "\n",
    "# test_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_data, train_targets)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassifier(\n",
       "  (lin1): Linear(in_features=1000, out_features=800, bias=True)\n",
       "  (act1): LeakyReLU(negative_slope=0.01)\n",
       "  (lin2): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (act2): LeakyReLU(negative_slope=0.01)\n",
       "  (lin3): Linear(in_features=500, out_features=100, bias=True)\n",
       "  (act3): LeakyReLU(negative_slope=0.01)\n",
       "  (lin4): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.lin1 =nn.Linear(1000, 800)\n",
    "        self.act1 =nn.LeakyReLU()\n",
    "        self.lin2 =nn.Linear(800, 500)\n",
    "        self.act2 =nn.LeakyReLU()\n",
    "        self.lin3 = nn.Linear(500, 100)\n",
    "        self.act3 = nn.LeakyReLU()\n",
    "        # self.lin4 = nn.Linear(200, 50)\n",
    "        # self.act4 = nn.LeakyReLU()\n",
    "        self.lin4 =nn.Linear(100, 5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.lin4(x)\n",
    "        # x = self.act4(x)\n",
    "        # x = self.lin5(x)\n",
    "        return x\n",
    "bow_model = BoWClassifier().to(device)\n",
    "bow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval() #*********#\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        output = model(imgs)\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1.0 test_acc: 0.612\n",
      "Epoch 1 loss 0.775 test_acc: 0.61\n",
      "Epoch 2 loss 0.589 test_acc: 0.59\n",
      "Epoch 3 loss 0.328 test_acc: 0.566\n",
      "Epoch 4 loss 0.139 test_acc: 0.59\n",
      "Epoch 5 loss 0.0694 test_acc: 0.569\n",
      "Epoch 6 loss 0.052 test_acc: 0.584\n",
      "Epoch 7 loss 0.0466 test_acc: 0.568\n",
      "Epoch 8 loss 0.032 test_acc: 0.579\n",
      "Epoch 9 loss 0.0356 test_acc: 0.58\n",
      "Epoch 10 loss 0.0333 test_acc: 0.58\n",
      "Epoch 11 loss 0.0275 test_acc: 0.563\n",
      "Epoch 12 loss 0.0245 test_acc: 0.561\n",
      "Epoch 13 loss 0.015 test_acc: 0.565\n",
      "Epoch 14 loss 0.0371 test_acc: 0.566\n",
      "Epoch 15 loss 0.02 test_acc: 0.566\n",
      "Epoch 16 loss 0.0114 test_acc: 0.564\n",
      "Epoch 17 loss 0.00985 test_acc: 0.56\n",
      "Epoch 18 loss 0.017 test_acc: 0.552\n",
      "Epoch 19 loss 0.0331 test_acc: 0.56\n",
      "Epoch 20 loss 0.0235 test_acc: 0.561\n",
      "Epoch 21 loss 0.0125 test_acc: 0.554\n",
      "Epoch 22 loss 0.0139 test_acc: 0.55\n",
      "Epoch 23 loss 0.00712 test_acc: 0.56\n",
      "Epoch 24 loss 0.00333 test_acc: 0.555\n",
      "Epoch 25 loss 0.0101 test_acc: 0.563\n",
      "Epoch 26 loss 0.00849 test_acc: 0.557\n",
      "Epoch 27 loss 0.0157 test_acc: 0.564\n",
      "Epoch 28 loss 0.0273 test_acc: 0.557\n",
      "Epoch 29 loss 0.00949 test_acc: 0.552\n",
      "Epoch 30 loss 0.0101 test_acc: 0.558\n",
      "Epoch 31 loss 0.017 test_acc: 0.543\n",
      "Epoch 32 loss 0.011 test_acc: 0.558\n",
      "Epoch 33 loss 0.0107 test_acc: 0.551\n",
      "Epoch 34 loss 0.00514 test_acc: 0.558\n",
      "Epoch 35 loss 0.0214 test_acc: 0.553\n",
      "Epoch 36 loss 0.0198 test_acc: 0.561\n",
      "Epoch 37 loss 0.0152 test_acc: 0.553\n",
      "Epoch 38 loss 0.0104 test_acc: 0.555\n",
      "Epoch 39 loss 0.00244 test_acc: 0.556\n",
      "Epoch 40 loss 0.0003 test_acc: 0.556\n",
      "Epoch 41 loss 5.7e-05 test_acc: 0.557\n",
      "Epoch 42 loss 4.07e-05 test_acc: 0.558\n",
      "Epoch 43 loss 3.2e-05 test_acc: 0.559\n",
      "Epoch 44 loss 2.59e-05 test_acc: 0.559\n",
      "Epoch 45 loss 2.13e-05 test_acc: 0.559\n",
      "Epoch 46 loss 1.78e-05 test_acc: 0.559\n",
      "Epoch 47 loss 1.5e-05 test_acc: 0.559\n",
      "Epoch 48 loss 1.28e-05 test_acc: 0.559\n",
      "Epoch 49 loss 1.09e-05 test_acc: 0.56\n",
      "Epoch 50 loss 9.36e-06 test_acc: 0.559\n",
      "Epoch 51 loss 8.05e-06 test_acc: 0.559\n",
      "Epoch 52 loss 6.96e-06 test_acc: 0.559\n",
      "Epoch 53 loss 6.03e-06 test_acc: 0.559\n",
      "Epoch 54 loss 5.22e-06 test_acc: 0.559\n",
      "Epoch 55 loss 4.53e-06 test_acc: 0.559\n",
      "Epoch 56 loss 3.92e-06 test_acc: 0.559\n",
      "Epoch 57 loss 3.4e-06 test_acc: 0.559\n",
      "Epoch 58 loss 2.94e-06 test_acc: 0.559\n",
      "Epoch 59 loss 2.56e-06 test_acc: 0.559\n",
      "Epoch 60 loss 2.22e-06 test_acc: 0.56\n",
      "Epoch 61 loss 1.94e-06 test_acc: 0.559\n",
      "Epoch 62 loss 1.69e-06 test_acc: 0.559\n",
      "Epoch 63 loss 1.48e-06 test_acc: 0.559\n",
      "Epoch 64 loss 1.29e-06 test_acc: 0.559\n",
      "Epoch 65 loss 1.13e-06 test_acc: 0.559\n",
      "Epoch 66 loss 9.95e-07 test_acc: 0.559\n",
      "Epoch 67 loss 8.74e-07 test_acc: 0.559\n",
      "Epoch 68 loss 7.68e-07 test_acc: 0.559\n",
      "Epoch 69 loss 6.76e-07 test_acc: 0.559\n",
      "Epoch 70 loss 5.97e-07 test_acc: 0.559\n",
      "Epoch 71 loss 5.27e-07 test_acc: 0.559\n",
      "Epoch 72 loss 4.66e-07 test_acc: 0.559\n",
      "Epoch 73 loss 4.12e-07 test_acc: 0.559\n",
      "Epoch 74 loss 3.65e-07 test_acc: 0.559\n",
      "Epoch 75 loss 3.24e-07 test_acc: 0.559\n",
      "Epoch 76 loss 2.87e-07 test_acc: 0.559\n",
      "Epoch 77 loss 2.56e-07 test_acc: 0.559\n",
      "Epoch 78 loss 2.28e-07 test_acc: 0.559\n",
      "Epoch 79 loss 2.03e-07 test_acc: 0.559\n",
      "Epoch 80 loss 1.8e-07 test_acc: 0.559\n",
      "Epoch 81 loss 1.6e-07 test_acc: 0.559\n",
      "Epoch 82 loss 1.43e-07 test_acc: 0.559\n",
      "Epoch 83 loss 1.28e-07 test_acc: 0.559\n",
      "Epoch 84 loss 1.14e-07 test_acc: 0.559\n",
      "Epoch 85 loss 1.02e-07 test_acc: 0.559\n",
      "Epoch 86 loss 9.15e-08 test_acc: 0.558\n",
      "Epoch 87 loss 8.22e-08 test_acc: 0.559\n",
      "Epoch 88 loss 7.33e-08 test_acc: 0.558\n",
      "Epoch 89 loss 6.6e-08 test_acc: 0.558\n",
      "Epoch 90 loss 5.9e-08 test_acc: 0.558\n",
      "Epoch 91 loss 5.3e-08 test_acc: 0.558\n",
      "Epoch 92 loss 4.76e-08 test_acc: 0.558\n",
      "Epoch 93 loss 4.27e-08 test_acc: 0.558\n",
      "Epoch 94 loss 3.86e-08 test_acc: 0.558\n",
      "Epoch 95 loss 3.47e-08 test_acc: 0.559\n",
      "Epoch 96 loss 3.07e-08 test_acc: 0.559\n",
      "Epoch 97 loss 2.8e-08 test_acc: 0.559\n",
      "Epoch 98 loss 2.53e-08 test_acc: 0.559\n",
      "Epoch 99 loss 2.29e-08 test_acc: 0.559\n",
      "Final Training Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bow_model.parameters(), lr=0.001)\n",
    "\n",
    "iters = []\n",
    "losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for n in range(100):\n",
    "    epoch_losses = []\n",
    "    for x, labels in iter(train_loader):\n",
    "        x, labels = x.to(device), labels.to(device)\n",
    "        bow_model.train()\n",
    "        out = bow_model(x).squeeze()\n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    loss_mean = np.array(epoch_losses).mean()\n",
    "    iters.append(n)\n",
    "    losses.append(loss_mean)\n",
    "    test_acc = get_accuracy(bow_model, test_loader)\n",
    "    print(f\"Epoch {n} loss {loss_mean:.3} test_acc: {test_acc:.3}\")\n",
    "    train_acc.append(get_accuracy(bow_model, train_loader)) # compute training accuracy\n",
    "    # val_acc.append(test_acc)  # compute validation accuracy\n",
    "\n",
    "\n",
    "print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "# print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gotowe modele z biblioteki sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineMultinomialNB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipelineComplementNB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('CNB', ComplementNB())\n",
    "])\n",
    "\n",
    "pipelineLinearSVM = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('LSVC', LinearSVC())\n",
    "])\n",
    "\n",
    "pipelineSVM = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('SVC', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(resampled_train_data))\n",
    "# print(type(resampled_train_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(resampled_train_data))\n",
    "# print(type(resampled_train_classes))\n",
    "# print(resampled_train_data.shape)\n",
    "# print(resampled_train_classes.shape)\n",
    "# print(resampled_train_data.values.reshape(-1))\n",
    "# print(resampled_train_classes.values.reshape(-1))\n",
    "# print(resampled_train_data.values.shape)\n",
    "# print(resampled_train_classes.values.reshape(-1,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5079300528670191\n"
     ]
    }
   ],
   "source": [
    "pipelineMultinomialNB.fit(resampled_train_data.values.flatten(), resampled_train_classes.values.flatten())\n",
    "predictMNB = pipelineMultinomialNB.predict(X_test.to_numpy().flatten())\n",
    "print(accuracy_score(y_test, predictMNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5453436356242375\n"
     ]
    }
   ],
   "source": [
    "pipelineComplementNB.fit(resampled_train_data.values.flatten(), resampled_train_classes.values.flatten())\n",
    "predictCNB = pipelineComplementNB.predict(X_test.to_numpy().flatten())\n",
    "print(accuracy_score(y_test, predictCNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5461569743798292\n"
     ]
    }
   ],
   "source": [
    "pipelineLinearSVM.fit(resampled_train_data.values.flatten(), resampled_train_classes.values.flatten())\n",
    "predictLSVM = pipelineLinearSVM.predict(X_test.to_numpy().flatten())\n",
    "print(accuracy_score(y_test, predictLSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5673037820252135\n"
     ]
    }
   ],
   "source": [
    "pipelineSVM.fit(resampled_train_data.values.flatten(), resampled_train_classes.values.flatten())\n",
    "predictSVM = pipelineSVM.predict(X_test.to_numpy().flatten())\n",
    "print(accuracy_score(y_test, predictSVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sposród przetestowanych przez nas gotowych modeli dostarczonych w bibliotece scikit-learn, najlepsze wyniki daje model SVM. Zauważyliśmy przy tym, że przeprowadzenie całości ostatniego pipeline'u zajmuje znacznie więcej czasu (~25-30 sek.) w porównaniu do pozostałych trzech modeli (~0.7 sek.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
